# Settings Configuration

## Overview
The Settings page in the Agentic-Threat-Hunter UI allows real-time configuration of query behavior, models, and result limits. Settings are stored in browser `localStorage` and sent with each WebSocket message to the backend.

## Available Settings

### Query Configuration

#### Default Splunk Index
- **Default:** `main`
- **Description:** The Splunk index to use when not explicitly specified in the query.
- **Effect:** Applied during the index policy phase; queries without an `index=` clause will have `index=<your_value>` injected.

#### Time Window Policy
- **Options:**
  - `off` – No automatic time windows
  - `normalize` – Fix invalid syntax only (e.g., convert `timeframe:end-1d` to `earliest=-1d`)
  - `infer` – Add time windows from natural language (e.g., "last 24 hours" → `earliest=-24h`)
- **Default:** `normalize`
- **Effect:** Controls how the backend interprets and rewrites time ranges in SPL queries.

#### Raw Result Limit
- **Range:** 10–500
- **Default:** 50
- **Description:** Maximum number of raw events to display in the UI.
- **Effect:** Applied to the final payload before sending results to the frontend. Useful for large result sets.

### AI Model Configuration

#### Splunk Query Generation Model
- **Default:** `splunk_hunter`
- **Description:** Ollama model used to generate SPL queries from natural language.
- **Effect:** Changes which model is invoked for SPL generation on each request.

#### Velociraptor Query Generation Model
- **Default:** `velociraptor_hunter`
- **Description:** Ollama model used to generate VQL queries from natural language.
- **Effect:** Changes which model is invoked for VQL generation on each request.

#### Summary Generation Model
- **Default:** `llama3:8b`
- **Description:** Ollama model used to summarize search results into human-readable paragraphs.
- **Effect:** Changes which model is invoked for summarization on each request.

## How Settings Work

1. **Frontend:** Settings are persisted in browser `localStorage` under the key `ath_settings`.
2. **WebSocket Payload:** When you send a message, the frontend packages it as JSON:
   ```json
   {
     "type": "ask",
     "question": "your query here",
     "settings": {
       "defaultIndex": "main",
       "timePolicyMode": "normalize",
       "splModel": "splunk_hunter",
       "vqlModel": "velociraptor_hunter",
       "summaryModel": "llama3:8b",
       "rawResultLimit": 50
     }
   }
   ```
3. **Backend:** The WebSocket handler parses the JSON and applies per-request settings, overriding environment defaults.
4. **Backward Compatibility:** If you send plain text (no JSON), the backend uses environment defaults from `.env`.

## Testing Settings

### Test 1: Change Default Index
1. Go to **Settings**.
2. Set "Default Splunk Index" to `security`.
3. Go to **AI Chat**.
4. Ask: "Show me failed logins"
5. **Expected:** The generated SPL will include `index=security` instead of `index=main`.

### Test 2: Change Time Policy Mode
1. Go to **Settings**.
2. Set "Time Window Policy" to `infer`.
3. Go to **AI Chat**.
4. Ask: "Show failed logins in the last 24 hours"
5. **Expected:** The final SPL will have `earliest=-24h` automatically appended.

### Test 3: Change Raw Result Limit
1. Go to **Settings**.
2. Set "Raw Result Limit" to `10`.
3. Go to **AI Chat**.
4. Ask: "Show me security events" (assuming you have >10 results).
5. **Expected:** Only the first 10 events are displayed in the raw results section.

### Test 4: Change Summary Model
1. Go to **Settings**.
2. Set "Summary Generation Model" to `llama3.2` (if available).
3. Go to **AI Chat**.
4. Ask: "Count failed logins"
5. **Expected:** The summary will be generated by the new model (style/quality may differ).

## Notes

- **Live Updates:** Changes take effect immediately for the next query; no restart required.
- **Model Availability:** Ensure the specified Ollama model is pulled locally (`ollama list`).
- **Validation:** The backend sanitizes and validates inputs (e.g., `rawResultLimit` is clamped to integers, `timePolicyMode` is lowercased).
- **Environment Fallback:** If settings are missing or malformed, the backend falls back to `.env` defaults.

## Environment Variables (Defaults)

If you prefer to set system-wide defaults, update `.env`:

```bash
DEFAULT_INDEX=main
TIME_POLICY_MODE=normalize
OLLAMA_MODEL=splunk_hunter
VQL_MODEL=velociraptor_hunter
SUMMARY_MODEL=llama3:8b
```

These are used when settings are not provided via the UI.
